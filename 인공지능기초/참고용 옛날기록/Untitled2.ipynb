{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO5tJcrEwOispCfxuGRUQfe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"CbtKoJ1yZmbR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":220},"id":"Sjkv_nLTZ0QK","executionInfo":{"status":"ok","timestamp":1634803647494,"user_tz":-540,"elapsed":19140,"user":{"displayName":"임경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14795974998298105210"}},"outputId":"c75f13d2-e68a-4841-8f88-680d14093ba5"},"source":["import io\n","import pandas as pd\n","from google.colab  import files\n","\n","uploaded=files.upload()\n","\n","\n","for fn in uploaded.keys():\n","    print('User uploaded file \"{name}\" with {length} bytes'.format(name=fn,length=len(uploaded[fn]))) #파일 이름과 파일 크기 얻어와 출력\n","    filename=fn\n","\n","\n","da=pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')))\n","print(da)\n","\n"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-a7abeb57-959e-4845-98fa-aa8d19071e43\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a7abeb57-959e-4845-98fa-aa8d19071e43\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving data.csv to data.csv\n","User uploaded file \"data.csv\" with 92 bytes\n","   tire  wing  ship  car  plane\n","0     0     0     1    0      0\n","1     1     0     0    1      0\n","2     1     1     0    0      1\n","3     0     0     1    0      0\n","4     0     0     1    0      0\n","5     0     1     0    0      1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4smswEur5JJ-","executionInfo":{"status":"ok","timestamp":1634805128463,"user_tz":-540,"elapsed":4134,"user":{"displayName":"임경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14795974998298105210"}},"outputId":"5ca6767b-5bb5-424e-b91b-aca9ecab590b"},"source":["from google.colab import drive\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","\n","#drive.mount('/content/gdrive')\n","\n","data = np.loadtxt('/content/gdrive/My Drive/data.csv', delimiter=',', skiprows=1, unpack=True, dtype=np.float32)\n","\n","x_data=np.transpose(data[0:2])\n","y_data=np.transpose(data[2:])\n","\n","model = Sequential()\n","model.add(Dense(input_dim=2, units=10, activation='relu'))\n","model.add(Dense(units=5, activation='relu'))\n","# 3개의 출력 유닛을 가진 소프트맥스 층을 추가\n","model.add(Dense(units=3, activation='softmax'))\n","print(\"=============initial weights==========\")\n","for weight in model.weights:\n","  print(weight)\n","  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01)\n",", loss='categorical_crossentropy'\n",", metrics=['accuracy'])\n","model.summary()\n","history = model.fit(x_data, y_data, epochs=100, batch_size=1)\n","\n","print(\"=============weights==========\")\n","for weight in model.weights:\n","  print(weight)\n","\n","print(\"=============test results==========\")\n","print(x_data)\n","# 모델 사용해서 결과 예측해보기\n","print(model.predict(x_data))\n","# 모델 사용해서 테스트 데이터로 성능 평가하기 (loss[0]와 Accuracy[1])\n","print(\"\\n Accuracy: %.4f\" % (model.evaluate(x_data, y_data)[1]))# list index\n","\n","print(\"===================================\")\n"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["=============initial weights==========\n","<tf.Variable 'dense_6/kernel:0' shape=(2, 10) dtype=float32, numpy=\n","array([[-0.03391457,  0.68692   , -0.14287293,  0.38072473, -0.00949317,\n","         0.5754978 , -0.6229894 ,  0.4288196 ,  0.30823833,  0.57092494],\n","       [-0.39731008,  0.29338926, -0.32092583, -0.3301555 ,  0.5330189 ,\n","         0.4467116 , -0.45752898, -0.00568444,  0.15137023,  0.19417387]],\n","      dtype=float32)>\n","<tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>\n","<tf.Variable 'dense_7/kernel:0' shape=(10, 5) dtype=float32, numpy=\n","array([[-0.2719728 , -0.5138032 , -0.1877456 , -0.5984582 , -0.02881491],\n","       [ 0.4842865 ,  0.22841102,  0.391684  ,  0.09850919, -0.60385185],\n","       [-0.02807921, -0.03196669, -0.5645621 , -0.24216571,  0.42716664],\n","       [-0.2934898 , -0.27114332, -0.18748036, -0.36072293,  0.2631685 ],\n","       [ 0.27881002,  0.10350049, -0.09068638,  0.09142935, -0.29710513],\n","       [ 0.6236921 ,  0.59562725, -0.01194775,  0.6210713 ,  0.472879  ],\n","       [ 0.05010015, -0.02978206, -0.40232807, -0.4220454 ,  0.18928456],\n","       [ 0.46470135, -0.30634895,  0.47918063, -0.0259552 ,  0.18793756],\n","       [-0.20962465,  0.33405375, -0.00387335,  0.4919104 ,  0.4345445 ],\n","       [ 0.1862691 , -0.16570732,  0.0766359 ,  0.04053003,  0.14112884]],\n","      dtype=float32)>\n","<tf.Variable 'dense_7/bias:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>\n","<tf.Variable 'dense_8/kernel:0' shape=(5, 3) dtype=float32, numpy=\n","array([[ 0.50469285, -0.26289153,  0.708191  ],\n","       [ 0.28449827,  0.13060057, -0.3390103 ],\n","       [-0.7433843 , -0.28797388, -0.6821609 ],\n","       [-0.00206804, -0.5714818 , -0.10223687],\n","       [ 0.28082126,  0.63290924,  0.44439393]], dtype=float32)>\n","<tf.Variable 'dense_8/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_6 (Dense)              (None, 10)                30        \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 5)                 55        \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 3)                 18        \n","=================================================================\n","Total params: 103\n","Trainable params: 103\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","6/6 [==============================] - 0s 3ms/step - loss: 1.1459 - accuracy: 0.5000\n","Epoch 2/100\n","6/6 [==============================] - 0s 2ms/step - loss: 1.0624 - accuracy: 0.8333\n","Epoch 3/100\n","6/6 [==============================] - 0s 2ms/step - loss: 1.0002 - accuracy: 0.8333\n","Epoch 4/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.9400 - accuracy: 0.8333\n","Epoch 5/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.8918 - accuracy: 0.8333\n","Epoch 6/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.8435 - accuracy: 0.8333\n","Epoch 7/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.7955 - accuracy: 0.8333\n","Epoch 8/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 1.0000\n","Epoch 9/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 1.0000\n","Epoch 10/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 1.0000\n","Epoch 11/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 1.0000\n","Epoch 12/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 1.0000\n","Epoch 13/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 1.0000\n","Epoch 14/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 1.0000\n","Epoch 15/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 1.0000\n","Epoch 16/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 1.0000\n","Epoch 17/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 1.0000\n","Epoch 18/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 1.0000\n","Epoch 19/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 1.0000\n","Epoch 20/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 1.0000\n","Epoch 21/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 1.0000\n","Epoch 22/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 1.0000\n","Epoch 23/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 1.0000\n","Epoch 24/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.2795 - accuracy: 1.0000\n","Epoch 25/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 1.0000\n","Epoch 26/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 1.0000\n","Epoch 27/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 1.0000\n","Epoch 28/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 1.0000\n","Epoch 29/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 1.0000\n","Epoch 30/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 1.0000\n","Epoch 31/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 1.0000\n","Epoch 32/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 1.0000\n","Epoch 33/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 1.0000\n","Epoch 34/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 1.0000\n","Epoch 35/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 1.0000\n","Epoch 36/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 1.0000\n","Epoch 37/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 1.0000\n","Epoch 38/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 1.0000\n","Epoch 39/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 1.0000\n","Epoch 40/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 1.0000\n","Epoch 41/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 1.0000\n","Epoch 42/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 1.0000\n","Epoch 43/100\n","6/6 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 1.0000\n","Epoch 44/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 1.0000\n","Epoch 45/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 1.0000\n","Epoch 46/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 1.0000\n","Epoch 47/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 1.0000\n","Epoch 48/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 1.0000\n","Epoch 49/100\n","6/6 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 1.0000\n","Epoch 50/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 1.0000\n","Epoch 51/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 1.0000\n","Epoch 52/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 1.0000\n","Epoch 53/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 1.0000\n","Epoch 54/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 1.0000\n","Epoch 55/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 1.0000\n","Epoch 56/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 1.0000\n","Epoch 57/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 1.0000\n","Epoch 58/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 1.0000\n","Epoch 59/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 1.0000\n","Epoch 60/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 1.0000\n","Epoch 61/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 1.0000\n","Epoch 62/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 1.0000\n","Epoch 63/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 1.0000\n","Epoch 64/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 1.0000\n","Epoch 65/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 1.0000\n","Epoch 66/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 1.0000\n","Epoch 67/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 1.0000\n","Epoch 68/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 1.0000\n","Epoch 69/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 1.0000\n","Epoch 70/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 1.0000\n","Epoch 71/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 1.0000\n","Epoch 72/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 1.0000\n","Epoch 73/100\n","6/6 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 1.0000\n","Epoch 74/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 1.0000\n","Epoch 75/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 1.0000\n","Epoch 76/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 1.0000\n","Epoch 77/100\n","6/6 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 1.0000\n","Epoch 78/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 1.0000\n","Epoch 79/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 1.0000\n","Epoch 80/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 1.0000\n","Epoch 81/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 1.0000\n","Epoch 82/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 1.0000\n","Epoch 83/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 1.0000\n","Epoch 84/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 1.0000\n","Epoch 85/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 1.0000\n","Epoch 86/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 1.0000\n","Epoch 87/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 1.0000\n","Epoch 88/100\n","6/6 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 1.0000\n","Epoch 89/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 1.0000\n","Epoch 90/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 1.0000\n","Epoch 91/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000\n","Epoch 92/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 1.0000\n","Epoch 93/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 1.0000\n","Epoch 94/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 1.0000\n","Epoch 95/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 1.0000\n","Epoch 96/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 1.0000\n","Epoch 97/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 1.0000\n","Epoch 98/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 1.0000\n","Epoch 99/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 1.0000\n","Epoch 100/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 1.0000\n","=============weights==========\n","<tf.Variable 'dense_6/kernel:0' shape=(2, 10) dtype=float32, numpy=\n","array([[-0.03391457,  0.50048226, -0.14287293,  0.82957935, -0.20343797,\n","         0.48892704, -0.6229894 ,  1.0246222 ,  0.83583003,  1.208075  ],\n","       [-0.39731008,  1.0919604 , -0.32092583, -1.014245  ,  1.5706515 ,\n","         1.2067044 , -0.45752898,  0.4194699 , -0.31042805,  0.64005715]],\n","      dtype=float32)>\n","<tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32, numpy=\n","array([ 0.        ,  0.00066345,  0.        ,  0.21864617,  0.20331219,\n","        0.00112051,  0.        ,  0.00301366, -0.00685028,  0.00467891],\n","      dtype=float32)>\n","<tf.Variable 'dense_7/kernel:0' shape=(10, 5) dtype=float32, numpy=\n","array([[-0.2719728 , -0.5138032 , -0.1877456 , -0.5984582 , -0.02881491],\n","       [ 0.6042639 ,  0.10124097,  0.7715017 ,  0.33465856, -0.07401539],\n","       [-0.02807921, -0.03196669, -0.5645621 , -0.24216571,  0.42716664],\n","       [-0.7637692 , -0.28920698,  0.34301078, -0.8284727 ,  0.84293354],\n","       [ 1.066057  , -0.08389006, -0.4196931 ,  1.1175102 , -0.36240417],\n","       [ 0.8542966 ,  0.45542622,  0.39573905,  0.9755432 ,  1.0448875 ],\n","       [ 0.05010015, -0.02978206, -0.40232807, -0.4220454 ,  0.18928456],\n","       [ 0.35100344, -0.41525438,  0.9810172 , -0.04565246,  0.8204992 ],\n","       [-0.50376755,  0.23255429,  0.60723734,  0.23514478,  1.1722184 ],\n","       [ 0.1566254 , -0.2980378 ,  0.5784714 ,  0.10117019,  0.79513144]],\n","      dtype=float32)>\n","<tf.Variable 'dense_7/bias:0' shape=(5,) dtype=float32, numpy=\n","array([-0.0562601 , -0.1488837 , -0.00737132, -0.04897045, -0.13548255],\n","      dtype=float32)>\n","<tf.Variable 'dense_8/kernel:0' shape=(5, 3) dtype=float32, numpy=\n","array([[ 0.0184612 , -0.47704372,  1.1875048 ],\n","       [ 0.15947692,  0.08657207, -0.22682002],\n","       [-1.4201897 ,  0.12011594, -0.7053074 ],\n","       [-0.5573547 , -1.1582721 ,  0.59048015],\n","       [-0.49558833,  1.1439779 ,  0.2172353 ]], dtype=float32)>\n","<tf.Variable 'dense_8/bias:0' shape=(3,) dtype=float32, numpy=array([ 1.9113709, -1.424641 , -1.441242 ], dtype=float32)>\n","=============test results==========\n","[[0. 0.]\n"," [1. 0.]\n"," [1. 1.]\n"," [0. 0.]\n"," [0. 0.]\n"," [0. 1.]]\n","[[9.3408060e-01 3.3233251e-02 3.2686096e-02]\n"," [3.1166317e-04 9.9789631e-01 1.7920324e-03]\n"," [3.3774495e-06 5.8210891e-04 9.9941456e-01]\n"," [9.3408060e-01 3.3233251e-02 3.2686096e-02]\n"," [9.3408060e-01 3.3233251e-02 3.2686096e-02]\n"," [9.3354483e-04 3.9380750e-05 9.9902713e-01]]\n","1/1 [==============================] - 0s 175ms/step - loss: 0.0347 - accuracy: 1.0000\n","\n"," Accuracy: 1.0000\n","===================================\n"]}]}]}