{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"액션러닝3참고.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1bbcU3VopYoVuzEql4EwiHbLUTYMAtmAq","authorship_tag":"ABX9TyPQqb27rRaCoSLirMFX7mRm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ruobGYB_Ubpe"},"outputs":[],"source":["import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pylab as plt\n","import numpy as np \n","import seaborn as sns\n","\n","file_path='/content/drive/MyDrive/@@@@@'\n","\n","\n","df=pd.read_csv(file_path)\n","# 두 연속형 변수 스캐터플롯 그리기\n","#plt.scatter(df.science, df.math)\n","\n","# 상관계수 확인\n","#row번호와 column 번호가 동일할때에는, \n","# 내 자신에 대한 상관계수 이므로 항상 1. \n","# default- method = 'pearson', \n","# method = \"kendall\", method= \"spearman\"\n","#corr = df.corr(method = 'pearson') \n","corr = df.corr() \n","corr\n","\n","#sns.lmplot(x='science', y='math',data=df)\n","\n","\n","# 회귀분석을 위해 종속(Y=수학), 독립(X=과학)\n","# 과학점수를 알면 수학점수를 예상 할 수 있다. \n","# 단순선형회귀 모형 \n","import statsmodels.api as sm\n","#OLS: ordinary least square = 최소제곱법\n","lin_reg = sm.OLS.from_formula\n"," (\"math ~ science\", df).fit()\n","lin_reg.summary()\n","\n","\n","#로지스틱\n","##passtest = [0.01,0.01,0.01,0.01,0.01,1,1,1,1,1]\n","#score = [51, 64, 60, 50, 68, 80, 90, 92, 99,83]\n","#df = pd.DataFrame({\"passtest\": passtest,\"score\": score } )\n","#print(df)\n","#상관분석\n","#sns.lmplot(x='score', y='passtest',data=df,logistic=True)\n","\n","\n","def sigmoid(x):\n"," return 1/(1+np.exp(-x))\n","#x = np.arange(-5.0, 5.0, 0.1)\n","#y = sigmoid(x)\n","#plt.plot(x, y, 'g')\n","#plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n","#plt.title('Sigmoid Function')\n","#plt.show()\n","#시그모이드 함수\n","\n","\n","\n","]:\n","# a는 1, b는 0임을 가정한 그래프.\n","import numpy as np # 넘파이 사용\n","import matplotlib.pyplot as plt # 맷플롯립 사용\n","def sigmoid(x):\n"," return 1/(1+np.exp(-x))\n","x = np.arange(-5.0, 5.0, 0.1)\n","y = sigmoid(x)\n","plt.plot(x, y, 'g')\n","plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n","plt.title('Sigmoid Function')\n","plt.show()\n","\n","\n","#직선의 방정식 y=ax에서 기울기 a를 변화시켜 시그모이드에\n","#넣어보자. 기울기는 직선과 유사하지만 S모양으로\n","def sigmoid(x):\n"," return 1/(1+np.exp(-x))\n","x = np.arange(-5.0, 5.0, 0.1)\n","y1 = sigmoid(0.5*x)\n","y2 = sigmoid(x)\n","y3 = sigmoid(2*x)\n","\n","\n","\n","plt.plot(x, y1, 'r', linestyle='--') # W의 값이 0.5일때\n","plt.plot(x, y2, 'g') # W의 값이 1일때\n","plt.plot(x, y3, 'b', linestyle='--') # W의 값이 2일때\n","plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n","plt.title('Sigmoid Function')\n","plt.show()\n","\n","\n","\n","\n","#1차식 경사하강법\n","\n","X = [0, 0.5, 1.0, 1.5, 2.0, 2.5] \n","Y = [0.3, 1.9, 2.4, 4.1, 6.8, 7.9]\n","# W, b를 -1.0~1.0 사이에 균등분포 갖는 shpae 1의 변수형 텐서로 설정\n","W = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n","b = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n","# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행\n","#학습률은 0.1로 고정\n","optimizer = tf.compat.v1.train.GradientDescentOptimizer\n","(learning_rate=0.1)\n","#optimizer =tf.optimizers.SGD(learning_rate=0.1)\n","#optimizer =tf.optimizers.Adam(learning_rate=0.2)\n","# 비용 함수 계산\n","@tf.function()\n","def cost_eval():\n"," # y = W(가중치 ) * x + b (bias , 편향)\n"," # W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용 \n"," hypothesis = W * X + b\n"," # mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 계산.\n"," cost = tf.reduce_mean(tf.square(hypothesis - Y))\n"," return cost\n"," \n","print(\"epoch W b cost\")\n","# 최적화를 10번 수행\n","for epoch in range(10):\n"," \n"," # 비용을 최소화 하는 것이 최종 목표\n"," optimizer.minimize(cost_eval, var_list=[W,b])\n"," # 손실, 가중치, 편향을 출력\n"," # numpy()함수는 변수의 배열만 출력\n"," print(epoch, W.numpy(), b.numpy(), cost_eval().numpy())\n"," # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인.\n","print(\"\\n=== Test ===\")\n","x=5.\n","print('X:', x, 'Y:', (W * x + b).numpy())\n","x=2.5\n","print('X:', x, 'Y:', (W * x + b).numpy())\n","# 그래프 그리기 위해 새로운 X값을 입력\n","new_X = tf.range(0, 3, 0.05)\n","# 선형 회귀직선을 이용하여 예측 Y값 계산\n","new_Y = W*new_X+b\n","plt.plot(X,Y,'ro', label='Sample Data') # 'ro'는 red circle\n","plt.plot(new_X, new_Y,'b-')\n","plt.xlabel('X')\n","plt.ylabel('Y')\n","plt.legend()\n","plt.show()\n","\n","####2차식\n","\n","\n","\n","X = tf.constant([0, 0.5, 1.0, 1.5, 2.0, 2.5]) \n","Y = tf.constant([0.3, 1.9, 2.4, 4.1, 6.8, 7.9])\n","a0 = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n","a1 = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n","a2 = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n","optimizer = tf.compat.v1.train.GradientDescentOptimizer\n","(learning_rate=0.01)\n","#optimizer =tf.optimizers.Adam(learning_rate=0.07)\n","#optimizer =tf.optimizers.SGD(learning_rate=0.01)\n","@tf.function()\n","def cost_eval():\n"," # y = a0+a1*x+a2*x^2 (2차함수)\n"," # W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용 \n"," hypothesis = a0+a1*X+(a2*(X**2))\n"," cost = tf.reduce_mean(tf.square(hypothesis - Y))\n"," return cost\n"," \n","print(\"epoch a0 a1 a2 cost\")\n","# 최적화를 10번 수행\n","for epoch in range(0,10, 1):\n"," \n"," # 손실 함수를 작성.\n"," # mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 계산.\n"," \n"," # 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 최적화를 수행\n"," # 비용을 최소화 하는 것이 최종 목표\n"," optimizer.minimize(cost_eval, var_list=\n"," [a0,a1,a2])\n"," # 손실, 가중치, 편향을 출력\n"," print(epoch, a0.numpy(), a1.numpy(), \n"," a2.numpy(), cost_eval().numpy())\n"," # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인.\n","print(\"\\n=== Test ===\")\n","x=5.\n","print('X:', x, 'Y:', (a0+a1*x+(a2*(x**2))).numpy())\n","x=2.5\n","print('X:', x, 'Y:', (a0+a1*x+(a2*(x**2))).numpy())\n","# 그래프 그리기 위해 새로운 X값을 입력\n","new_X = tf.range(0, 3, 0.05)\n","# 비선형 회귀직선을 이용하여 예측 Y값 계산\n","new_Y = a0+a1*new_X+(a2*(new_X**2))\n","plt.plot(X,Y,'ro', label='Sample Data') # 'ro'는 red circle\n","plt.plot(new_X, new_Y,'b-')\n","plt.xlabel('X')\n","plt.ylabel('Y')\n","plt.legend()\n","plt.show()\n","\n","\n","\n","\n","\n","\n","##############12장\n","\n","\n","#로지스틱 회귀분석\n","\n","\n","\n","\n","from sklearn import model_selection\n","from sklearn import metrics\n","from sklearn import datasets\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","\n","## 데이터 전처리\n","#불필요 컬럼 삭제 (x)\n","del df['PassengerId']\n","del df['Name']\n","del df['Ticket']\n","del df['Cabin']\n","\n","\n","df.dropna(thresh=int(len(df) * 0.5), axis=1) #결측치 제거\n","df['Embarked'] = df['Embarked'].fillna('S') # 최다빈도 ‘S’로 대체\n","df['Age']=df['Age'].fillna(df['Age'].mean()) # 나이 평균값으로 대체\n","df\n","\n","\n","\n","#범주형 컬럼 처리 (x) \n","df['Sex']=df['Sex'].astype('category') \n","df['Pclass']=df['Pclass'].astype('category') \n","df['Embarked']=df['Embarked'].astype('category')\n","# 문자를 숫자로 (One-Hot Encoding)하는 함수\n","# 가변수(dummy variable)=>0과 1로만 이루어진 열을 생성\n","df = pd.get_dummies(df)\n","df\n","\n","\n","#독립변수와 종속변수 구분 (x, y)\n","x_data=df.iloc[:,1:]\n","y_data=df.iloc[:,0]\n","#~values가 있는 경우와 없는 경우 차이\n","x_data = x_data.values\n","y_data = y_data.values\n","print(x_data)\n","print(y_data)\n","#슬라이스 조심! \n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pylab as plt\n","import numpy as np \n","import seaborn as sns\n","import tensorflow as tf\n","\n","\n","\n","file_path='/content/drive/MyDrive/act3.csv'\n","df=pd.read_csv(file_path)\n","\n","#science를 독립변수로 하여 math(종속변수)의 값을 예측하는 선형회귀함수(linear regression)을 만들어보자. \n","#초기 가중치 분포, 최적화방법(optimizer)은 학생이 결정한다. 결과는 아래 그림처럼 출력되도록 한다. [2점]\n","\n","\n","\n","# W, b를 -1.0~1.0 사이에 균등분포 갖는 shpae 1의 변수형 텐서로 설정\n","#W = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n","#b = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n","# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행\n","#학습률은 0.1로 고정\n","#optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.1)\n","#optimizer =tf.optimizers.Adam(learning_rate=0.00000001)\n","\n","#최적화방법 결정\n","\n","# 비용 함수 계산\n","#@tf.function()\n","#def cost_eval():\n"," # y = W(가중치 ) * x + b (bias , 편향)\n"," # W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용 \n"," #hypothesis = W * X + b  1차식\n"," # mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 계산.\n"," # hypothesis = a0+a1*X+(a2*(X**2))\n"," # cost = tf.reduce_mean(tf.square(hypothesis - Y))\n","#  return cost\n"," \n","#print(\"epoch W b cost\")\n","# 최적화를 10번 수행\n","#for epoch in range(20):\n"," \n"," # 비용을 최소화 하는 것이 최종 목표\n","# optimizer.minimize(cost_eval, var_list=[W,b])\n"," # 손실, 가중치, 편향을 출력\n"," # numpy()함수는 변수의 배열만 출력\n","# print(epoch, W.numpy(), b.numpy(), cost_eval().numpy())\n"," # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인.\n","#print(\"\\n=== Test ===\")\n","#x=5.\n","#print('X:', x, 'Y:', (W * x + b).numpy())\n","#x=2.5\n","#print('X:', x, 'Y:', (W * x + b).numpy())\n","\n","\n","\n","\n","X =df['science']\n","Y = df['math']\n","a0 = tf.Variable(tf.random.normal([1], 0, 1.0))\n","a1 = tf.Variable(tf.random.normal([1], 0, 1.0))\n","a2 = tf.Variable(tf.random.normal([1], 0, 1.0))\n","#optimizer =tf.optimizers.Adam(learning_rate=0.000000001)\n","#optimizer =tf.optimizers.Adam(learning_rate=0.07)\n","optimizer =tf.optimizers.SGD(learning_rate=0.000000001)\n","\n","\n","@tf.function()\n","def cost_eval():\n"," # y = a0+a1*x+a2*x^2 (2차함수)\n"," # W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용 \n"," hypothesis = a0+a1*X+(a2*(X**2))\n"," cost = tf.reduce_mean(tf.square(hypothesis - Y))\n"," return cost\n"," \n","print(\"epoch a0 a1 a2 cost\")\n","# 최적화를 10번 수행\n","\n","for epoch in range(0,100, 1):\n"," \n"," # 손실 함수를 작성.\n"," # mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 계산.\n"," \n"," # 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 최적화를 수행\n"," # 비용을 최소화 하는 것이 최종 목표\n"," optimizer.minimize(cost_eval, var_list=[a0,a1,a2])\n"," # 손실, 가중치, 편향을 출력\n"," print(epoch, a0.numpy(), a1.numpy(), \n"," a2.numpy(), cost_eval().numpy())\n"," # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인.\n","print(\"\\n=== Test ===\")\n","x=5.\n","print('X:', x, 'Y:', (a0+a1*x+(a2*(x**2))).numpy())\n","x=2.5\n","print('X:', x, 'Y:', (a0+a1*x+(a2*(x**2))).numpy())\n","# 그래프 그리기 위해 새로운 X값을 입력\n","new_X = tf.range(60,90, 0.05)\n","# 비선형 회귀직선을 이용하여 예측 Y값 계산\n","new_Y = a0+a1*new_X+(a2*(new_X**2))\n","plt.plot(X,Y,'ro', label='Sample Data') # 'ro'는 red circle\n","plt.plot(new_X, new_Y,'b-')\n","plt.xlabel('X')\n","plt.ylabel('Y')\n","plt.legend()\n","plt.show()\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2vpfZo4Ch-Pe","executionInfo":{"status":"ok","timestamp":1639381307104,"user_tz":-540,"elapsed":1690,"user":{"displayName":"임경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14795974998298105210"}},"outputId":"d6e41882-ae16-4e41-cade-89cde135892b"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch a0 a1 a2 cost\n","0 [0.56957924] [0.03855504] [0.7412454] 24403616.0\n","1 [0.56956965] [0.03775842] [0.67435676] 20134016.0\n","2 [0.56956095] [0.03703487] [0.6136006] 16611421.0\n","3 [0.569553] [0.03637766] [0.5584147] 13705132.0\n","4 [0.5695458] [0.03578072] [0.5082883] 11307322.0\n","5 [0.56953925] [0.03523853] [0.46275765] 9329029.0\n","6 [0.5695333] [0.03474606] [0.42140132] 7696855.5\n","7 [0.5695279] [0.03429876] [0.38383663] 6350245.0\n","8 [0.56952304] [0.03389248] [0.34971592] 5239234.0\n","9 [0.56951857] [0.03352347] [0.31872347] 4322603.5\n","10 [0.5695145] [0.0331883] [0.29057246] 3566345.8\n","11 [0.5695108] [0.03288388] [0.2650024] 2942401.5\n","12 [0.5695075] [0.03260739] [0.24177666] 2427621.8\n","13 [0.56950444] [0.03235626] [0.2206803] 2002906.9\n","14 [0.5695017] [0.03212817] [0.2015181] 1652499.8\n","15 [0.5694992] [0.031921] [0.18411273] 1363399.2\n","16 [0.5694969] [0.03173285] [0.16830312] 1124879.4\n","17 [0.56949484] [0.03156196] [0.15394296] 928090.4\n","18 [0.569493] [0.03140676] [0.14089938] 765731.44\n","19 [0.5694913] [0.0312658] [0.12905166] 631778.6\n","20 [0.5694898] [0.03113777] [0.11829015] 521261.88\n","21 [0.5694884] [0.03102151] [0.10851528] 430080.8\n","22 [0.56948715] [0.03091591] [0.09963659] 354852.84\n","23 [0.569486] [0.03082002] [0.09157192] 292786.53\n","24 [0.56948495] [0.03073293] [0.08424664] 241579.33\n","25 [0.569484] [0.03065384] [0.07759295] 199331.23\n","26 [0.56948316] [0.03058202] [0.07154928] 164474.8\n","27 [0.5694824] [0.0305168] [0.06605971] 135716.78\n","28 [0.5694817] [0.03045757] [0.06107343] 111990.22\n","29 [0.569481] [0.03040379] [0.0565443] 92414.805\n","30 [0.5694804] [0.03035496] [0.05243042] 76264.28\n","31 [0.5694799] [0.03031062] [0.0486937] 62939.434\n","32 [0.5694794] [0.03027036] [0.04529957] 51945.875\n","33 [0.569479] [0.03023381] [0.04221663] 42875.742\n","34 [0.5694786] [0.03020062] [0.03941633] 35392.5\n","35 [0.5694782] [0.03017049] [0.03687277] 29218.504\n","36 [0.5694779] [0.03014314] [0.03456241] 24124.709\n","37 [0.5694776] [0.03011832] [0.03246387] 19922.121\n","38 [0.5694773] [0.03009578] [0.03055772] 16454.805\n","39 [0.5694771] [0.03007533] [0.02882634] 13594.125\n","40 [0.56947684] [0.03005677] [0.02725369] 11233.943\n","41 [0.56947666] [0.03003992] [0.02582522] 9286.698\n","42 [0.5694765] [0.03002464] [0.02452772] 7680.138\n","43 [0.5694763] [0.03001077] [0.02334917] 6354.661\n","44 [0.5694761] [0.02999819] [0.02227868] 5261.0874\n","45 [0.569476] [0.02998678] [0.02130633] 4358.8438\n","46 [0.5694759] [0.02997643] [0.02042313] 3614.4553\n","47 [0.56947577] [0.02996704] [0.0196209] 3000.3032\n","48 [0.56947565] [0.02995853] [0.01889223] 2493.6025\n","49 [0.56947553] [0.02995082] [0.01823035] 2075.5532\n","50 [0.5694755] [0.02994383] [0.01762916] 1730.6448\n","51 [0.5694754] [0.0299375] [0.01708309] 1446.0815\n","52 [0.56947535] [0.02993176] [0.01658708] 1211.3047\n","53 [0.5694753] [0.02992657] [0.01613655] 1017.60406\n","54 [0.56947523] [0.02992186] [0.01572732] 857.7931\n","55 [0.5694752] [0.02991761] [0.01535562] 725.9423\n","56 [0.5694751] [0.02991376] [0.01501799] 617.16003\n","57 [0.56947505] [0.02991028] [0.01471131] 527.4101\n","58 [0.569475] [0.02990713] [0.01443275] 453.36276\n","59 [0.56947494] [0.02990429] [0.01417973] 392.2707\n","60 [0.56947494] [0.02990172] [0.01394991] 341.86697\n","61 [0.56947494] [0.0298994] [0.01374116] 300.28195\n","62 [0.56947494] [0.02989732] [0.01355154] 265.97256\n","63 [0.56947494] [0.02989543] [0.01337931] 237.66592\n","64 [0.56947494] [0.02989374] [0.01322287] 214.31166\n","65 [0.56947494] [0.02989222] [0.01308078] 195.0434\n","66 [0.56947494] [0.02989085] [0.01295171] 179.1464\n","67 [0.56947494] [0.02988963] [0.01283447] 166.0306\n","68 [0.56947494] [0.02988853] [0.01272798] 155.2095\n","69 [0.56947494] [0.02988755] [0.01263126] 146.28168\n","70 [0.56947494] [0.02988667] [0.0125434] 138.91588\n","71 [0.56947494] [0.0298859] [0.0124636] 132.83875\n","72 [0.56947494] [0.0298852] [0.01239111] 127.82482\n","73 [0.56947494] [0.02988459] [0.01232527] 123.6882\n","74 [0.56947494] [0.02988405] [0.01226546] 120.275246\n","75 [0.56947494] [0.02988357] [0.01221114] 117.459435\n","76 [0.56947494] [0.02988316] [0.0121618] 115.136284\n","77 [0.56947494] [0.02988279] [0.01211698] 113.219574\n","78 [0.56947494] [0.02988248] [0.01207627] 111.6382\n","79 [0.56947494] [0.02988221] [0.0120393] 110.333496\n","80 [0.56947494] [0.02988198] [0.01200571] 109.25708\n","81 [0.56947494] [0.02988179] [0.0119752] 108.36897\n","82 [0.56947494] [0.02988163] [0.01194749] 107.636215\n","83 [0.56947494] [0.0298815] [0.01192232] 107.03167\n","84 [0.56947494] [0.0298814] [0.01189946] 106.53289\n","85 [0.56947494] [0.02988132] [0.01187869] 106.12137\n","86 [0.56947494] [0.02988127] [0.01185982] 105.78187\n","87 [0.56947494] [0.02988124] [0.01184269] 105.50174\n","88 [0.56947494] [0.02988122] [0.01182713] 105.27061\n","89 [0.56947494] [0.02988123] [0.01181299] 105.07993\n","90 [0.56947494] [0.02988124] [0.01180015] 104.92259\n","91 [0.56947494] [0.02988128] [0.01178849] 104.79279\n","92 [0.56947494] [0.02988132] [0.01177789] 104.68568\n","93 [0.56947494] [0.02988138] [0.01176827] 104.597305\n","94 [0.56947494] [0.02988144] [0.01175953] 104.5244\n","95 [0.56947494] [0.02988152] [0.01175159] 104.46425\n","96 [0.56947494] [0.02988161] [0.01174437] 104.4146\n","97 [0.56947494] [0.0298817] [0.01173782] 104.37363\n","98 [0.56947494] [0.0298818] [0.01173187] 104.33982\n","99 [0.56947494] [0.02988191] [0.01172647] 104.31194\n","\n","=== Test ===\n","X: 5.0 Y: [1.0120461]\n","X: 2.5 Y: [0.7174701]\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5zWc/7/8ceLSlt8HSqJ1LAbRWcTOaQct9h1lmytSZiVFbLYll3Wod/WsiTbsq1UbEXatYVQkhKVphMdkKUynYzaUOn8+v3xvpqmmqmZ6Zrrcx2e99ttbtd1fa7Pdc2rT1fXq/fp9TZ3R0REBOCAqAMQEZHkoaQgIiKFlBRERKSQkoKIiBRSUhARkUKVog5gf9SsWdOzsrKiDkNEJKXMnDnzG3evVdxzKZ0UsrKyyMvLizoMEZGUYmZLSnpO3UciIlKowpKCmT1nZl+b2bwix44ws/Fmtih2e3jsuJlZfzP73Mw+MrOWFRWXiIiUrCJbCkOA9rsd6wVMcPcGwITYY4AOQIPYTy7wdAXGJSIiJaiwMQV3n2xmWbsdvhRoF7s/FHgX+G3s+PMeam5MM7PDzKyOu68o6+/dsmUL+fn5bNy4sbyhS5xUrVqVunXrUrly5ahDEZFSSvRAc+0iX/Qrgdqx+8cAXxU5Lz92rMxJIT8/n0MOOYSsrCzMbL+ClfJzd1avXk1+fj7HHXdc1OGISClFNtAcaxWUuRqfmeWaWZ6Z5RUUFOzx/MaNG6lRo4YSQsTMjBo1aqjFJhJvw4ZBVhYccEC4HTYsrm+f6KSwyszqAMRuv44dXwYcW+S8urFje3D3ge6e7e7ZtWoVO81WCSFJ6O9BJM6GDYPcXFiyBNzDbW5uXBNDopPCGCAndj8HGF3k+HWxWUitgW/LM54gIpLW7rsPNmzY9diGDeF4nFTklNQRwFTgRDPLN7MbgD7ABWa2CDg/9hhgLPAF8DnwD+CWioorEXr37s3JJ59M06ZNad68OdOnT6/Q39euXbsyLeLr2rUrxx13HM2aNeOEE07guuuuIz8/f5+v69evHxt2/0CKSOIsXVq24+VQYUnB3a919zruXtnd67r7IHdf7e7nuXsDdz/f3dfEznV3/7W7/9jdm7h74pYpx7l/burUqbz22mvMmjWLjz76iLfffptjjz123y9MsEcffZS5c+fy6aef0qJFC84991w2b96819coKYhErF69sh0vh8xe0VwB/XMrVqygZs2aHHTQQQDUrFmTo48+GoCHHnqIVq1a0bhxY3Jzc9mx6127du3o2bMn2dnZNGrUiBkzZnDFFVfQoEEDfv/73wOwePFiGjZsSOfOnWnUqBFXXXVVsV/Q48aN4/TTT6dly5ZcffXVrFu3bq/xmhk9e/bkqKOO4o033gCge/fuZGdnc/LJJ/PAAw8A0L9/f5YvX84555zDOeecU+J5Iqlo8GBYVuwoZpLp3RuqVdv1WLVq4Xi8uHvK/pxyyim+uwULFuxxrET167uHdLDrT/36pX+P3Xz//fferFkzb9CggXfv3t3ffffdwudWr15deL9Lly4+ZswYd3dv27at33PPPe7u3q9fP69Tp44vX77cN27c6Mccc4x/8803/uWXXzrgU6ZMcXf366+/3h999NHC18+YMcMLCgq8TZs2vm7dOnd379Onjz/44IN7xJiTk+Mvv/zyLsduv/1279Onzy5xbt261du2betz586NXa76XlBQsMefZ/fziirT34dIgm3f7t6rV/hnf+edUUdTSv/8Z/iOMgu3//xnmd8CyPMSvlczu6VQAf1zBx98MDNnzmTgwIHUqlWLa665hiFDhgAwceJETjvtNJo0acI777zD/PnzC193ySWXANCkSRNOPvlk6tSpw0EHHcTxxx/PV1+FJRzHHnssZ555JgBdunRhypQpu/zuadOmsWDBAs4880yaN2/O0KFDWbKkxLpXu/Aie3WPHDmSli1b0qJFC+bPn8+CBQuKfU1pzxNJRps3Q04O9OkTOgj69o06olLq3BkWL4bt28Nt585xffuUrpK63+rVC11GxR3fDwceeCDt2rWjXbt2NGnShKFDh9KpUyduueUW8vLyOPbYY/njH/+4yxz+Hd1NBxxwQOH9HY+3bt0K7DnFc/fH7s4FF1zAiBEjyhzz7NmzOe+88/jyyy957LHHmDFjBocffjhdu3Ytdq1Bac8TSUbffQdXXglvvw0PPxwm7+z3DOphw8IbLV0avkN69477F3YiZHZLoQL65z799FMWLVpU+HjOnDnUr1+/8AuzZs2arFu3jlGjRpX5vZcuXcrUqVMBGD58OGedddYuz7du3Zr333+fzz//HID169fz2Wef7fU93Z3+/fuzYsUK2rdvz3fffUf16tU59NBDWbVqVeE4A8AhhxzC999/D7DX80SS2fLl0LYtTJwIzz0Hv/99nBJCBa8fSJTMbinsyOJxzO7r1q2jR48erF27lkqVKvGTn/yEgQMHcthhh3HTTTfRuHFjjjrqKFq1alXm9z7xxBMZMGAA3bp146STTqJ79+67PF+rVi2GDBnCtddey6ZNmwB45JFHOOGEE/Z4r7vvvpuHH36YDRs20Lp1ayZOnEiVKlVo1qwZLVq0oGHDhrt0VwHk5ubSvn17jj76aCZOnFjieSLJauFCaN8eVq+G114L9+Nib+sHUqy1YEX7klNNdna27z4/f+HChTRq1CiiiCrO4sWL+dnPfsa8efP2fXISSde/D0k9778PP/85VK4MY8fCKafE8c0POCC0EHZnFvr+k4yZzXT37OKey+zuIxHJCK+8AuefDzVrwtSpcU4IkJD1A4mipJAisrKyUq6VIJIM/vrXMKjcvDl88AEcf3wF/JJErB9IkLRMCqncJZZO9PcgUdq+HXr1gh49QrfRhAmhpVAhOneGgQOhfv3QZVS/fnicYuMJkIYDzVWrVmX16tUqnx0xj+2nULVq1ahDkQy0aRN07Qovvgg33wxPPQWVKvrbrnPnlEwCu0u7pFC3bl3y8/Mpbq8FSawdO6+JJNKaNXD55TB5cliYds89cZhymkHSLilUrlxZO32JZKgvv4SLLoIvvoARI6BTp6gjSj1plxREJDPl5cHFF8OWLTB+PJx9dtQRpaa0HGgWkczy6qthlXK1amGGkRJC+SkpiEhKGzAALrsMTjoJpk2Dhg2jjii1KSmISEravh3uvhtuvTV0G737LtSuHXVUqU9jCiKScjZuhOuug5dfhltugf794cADo44qPSgpiEhKWb0aLr001DJ69FH4zW805TSelBREJGX8979hyumSJTByJFx9ddQRpR8lBRFJCdOnh3IV27aFkhWq1l4xNNAsIklv9Gg45xw45JBQ5TThCWHYMMjKCiWys7JScvOc0lJSEJGk9tRToWxF06YhIRSzZ1TFSqNd1UpDSUFEktK2bWEQ+bbbwsDyO+/AkUdGEMjedlVLQxpTEJGks349dOkC//lPSAqPPx7hlNOlS8t2PMWppSAiSWX58lCyYsyYsP7gyScjXoOQRruqlYaSgogkjY8+gtNOg08+CUmhR4+oIyKtdlUrDSUFEUkKY8eGWUXuMGVKKF2RFNJoV7XSiCQpmNntZjbPzOab2R2xY0eY2XgzWxS7PTyK2EQk8QYMCGsQGjQI6xGaN486ot107gyLF4eCS4sXp21CgAiSgpk1Bm4CTgWaAT8zs58AvYAJ7t4AmBB7LCJpbNs2uOOOnUXtJk+GY46JOqrMFkVLoREw3d03uPtWYBJwBXApMDR2zlDgsghiE5EEWbcurD948smQGF55BQ4+OOqoJIqkMA9oY2Y1zKwacBFwLFDb3VfEzlkJFFsE18xyzSzPzPK0D7NIalq2LGyE8/rroevoiSdU5TRZJDwpuPtCoC8wDngTmANs2+0cB7yE1w9092x3z65Vq1ZFhysicTZ7Npx6KixaBK+9FkpfRyqDSliURiQDze4+yN1Pcfezgf8BnwGrzKwOQOz26yhiE5GK8+qr0KZNaBW8/z506BBxQBlWwqI0opp9dGTsth5hPGE4MAbIiZ2SA4yOIjYRqRj9+4dtMxs1CjOMmjaNOiIyroRFaURV5uJfZlYD2AL82t3XmlkfYKSZ3QAsATpGFJuIxNHWrdCzJ/z1r2Fg+YUXoHr1qKOKybASFqURSVJw9zbFHFsNnBdBOCJSQb7/Hq65Bt54A+66C/r2DV33SaNevdBlVNzxDJVMfz0ikkaWLoWzzoJx4+Dvfw9bZyZVQoCMK2FRGsn2VyQiaWDatDDDaPHiUL4iNzfqiEqQYSUsSkNJQUTiavhwaNcujBtMmwYXXljMSck0DTSDSliUhpKCiMTF9u3whz+E79TTToMPPwwzjfagaaBJTUlBRPbbhg1hQPmRR6BbNxg/HmrUKOFkTQNNakoKIrJfdpSs+Ne/4C9/gWefhSpV9vKCRE4DTaZuqhSh7ThFpNzy8uCSS8LU0zFj4Gc/K8WLEjUNdEc31Y5WyY5uKsj4cYO9UUtBRMrl5ZdDC6FKFfjgg1ImBEjcNFB1U5WLkoKIlIk7PPwwdOwILVqEAeUmTcrwBomaBqrVyuWipCAiO+2jD/6HH+AXv4D774df/hImTIAjjyzH70nENNCSuqMyeLVyaSgpiEiwj6miK1fCOefAiy/Cn/4EQ4dC1aoRx7w3Wq1cLkoKIhLspQ9+zpywQvnjj+Hf/4ZevULPT1LTauVy0ewjEQlK6Gv/z5IWdD4TjjgCpkwJ4wgpo3NnJYEyUktBJBnEYz79/r7Hbn3tDvTlHq7gXzRuHAaUUyohSLkoKYhELR5lH+LxHkX64H+gKtfxPL3oS8fWS3n3XahTp2x/LElNFrZDTk3Z2dmel5cXdRgi+ycrq/jFXPXrh5k5iXoPgGHDWPbb/ly+7ClmcCoPXTmX37/cLPnHD6RMzGymu2cX95zGFESiFo/59HGakz/9J525fHtnvj8YXnkBLrusWZleL6lP3UciUYvHfPo4vMfzz0PbtmGa6QcfhP2UJfMoKYhELR7z6ffjPbZtg7vvhpwcOOOMcqxQlrSipCAStXjMpy/ne6xdG2oWPfYY/PrX8NZbULPmfv55JKVpoFkkQ336aahw+sUXMGBAEm+ZKXGngWYR2cWbb0KnTlC5cqhfdPbZUUckyULdRyIZxD1shHPxxaGHKS9PCUF2paQgkiE2boSuXeGuu+Dyy8MMo/r1o45Kko2SgkgGWL4c2rUL004ffBBGjoTq1aOOSpKRxhRE0tyMGWHNwbffhgqnl18edUSSzNRSEEljw4ZBmzY7t8xUQpB9iSQpmFlPM5tvZvPMbISZVTWz48xsupl9bmYvmVmVKGITSQdbt4YFaV26QOvWobXQtGnUUUkqSHhSMLNjgNuAbHdvDBwIdAL6Ak+4+0+A/wE3JDo2kXSwejV06BAWpN1yC4wfrwVpUnpRdR9VAn5kZpWAasAK4FxgVOz5oYAqr4iU0dy50KoVTJ4MgwaFRWmVK0cdlaSShCcFd18GPAYsJSSDb4GZwFp33xo7LR84prjXm1mumeWZWV5BQUEiQhZJCS+9BKefDps2haTQrVvUEUkqiqL76HDgUuA44GigOtC+tK9394Hunu3u2bVq1aqgKEVSx7ZtcM89YYVyy5YwcyacdlrUUUmqimJK6vnAl+5eAGBm/wbOBA4zs0qx1kJdYFkEsYmklDVrQjIYPx66d4d+/cJMI5HyimJMYSnQ2syqmZkB5wELgInAVbFzcoDREcQmkjI++giys2HSJHj2Wfjb35QQZP9FMaYwnTCgPAv4OBbDQOC3wJ1m9jlQAxiU6NhEUsXIkTvHDyZNghs0V0/iJJIVze7+APDAboe/AE6NIByRlLFtG9x7L/z5z3DmmTBqFBx1VNRRSTpRmQuRFLFmDVx7LYwbp/EDqThKCiIp4OOPQ/2i/Hz4xz/gxhujjkjSlWofiSS5kSNDqYoffgjjB0oIUpGUFESS1LZt0KsXXHMNNG8e1h+0bh11VJLu1H0kkoS++QZ+8Yuw/uDmm+HJJzV+IImhpCCSZPLy4MorYdUqjR9I4qn7KBMMGwZZWXDAAeF22LCoI0ofcb62gwbBWWeF+1OmKCFI4qmlkO6GDYPcXNiwITxesiQ8BujcObq40kEcr+3GjdCjR1iZfMEFMHy4yl1LNMzdo46h3LKzsz0vLy/qMJJbVlb4stpd/fqweHGio0kvcbq2S5bAVVeFbqN774WHHoIDD4xblCJ7MLOZ7p5d3HNqKaS7pUvLdlxKLw7Xdvz4sCBtyxb4z3/g0kvjFJtIOWlMId3Vq1e241J6+3Ftt2+HP/0J2rcPZSpmzFBCkOSgpJDueveGatV2PVatWjgu+6ec1/bbb+GKK0JXUceOMH06nHBCBcYpUgZKCumuc2cYODD0c5uF24EDNcgcD+W4tvPmhe0yX3891C4aPhyqV09gzCL7oIFmkQR58cVQ4vr//i+UrmjTJuqIJFPtbaBZLQWRCrZlC/TsGQaUW7aEWbOUECR5afaRSAVauTKMG7z3Htx+Ozz6KFSuHHVUIiVTUhCpIO+9F4rZffttGDu49tqoIxLZN3UficSZe2gRnHMOHHwwTJumhCCpQy0FkThauxa6doXRo8Mq5UGDwsCySKpQUhCJk1mz4Oqrw4LmJ58MtYzMoo5KpGzUfSSyn9xDieszzoDNm2HyZLjtNiUESU1KCiL7Yf360F2Umwtt28Ls2XD66VFHJVJ+JSYFMxtrZlmJC0UktXz6adge84UX4MEHYexYlbuW1Le3lsJgYJyZ3WdmmlktUsTIkZCdHdYhvPUW3H+/yl1LeigxKbj7y0BL4P+APDO7y8zu3PGTsAhFdhfhTnKbN4dFaNdcA02ahO6iCy7Yx4u0852kkH3NPtoMrAcOAg4Btld4RCJ7E+FOckuX7qxq2rMn9O1bitXJ2vlOUkyJBfHMrD3wODAGeMjdNyQysNJQQbwMFNFOcm++Gb7Dt2yBwYPhyitL+ULtfCdJqLwF8e4Drnb3XvFMCGZ2opnNKfLznZndYWZHmNl4M1sUuz08Xr9T0kiCd5Lbti2MF1x0EdStCzNnliEh7C0u7XwnSWpvYwpt3H1+vH+hu3/q7s3dvTlwCrABeAXoBUxw9wbAhNhjkV0lcCe5lSvhpz+Fhx+GnByYOhUaNCjjm2jnO0kxUa9TOA/4r7svAS4FhsaODwUuiywqSV4J2knunXegeXN4//1QqmLw4D1/balo5ztJMVEnhU7AiNj92u6+InZ/JVA7mpAkqVXwTnLbtsEDD8D558Phh4e9k7t1S954ReItsp3XzKwKsBw42d1Xmdladz+syPP/c/c9xhXMLBfIBahXr94pS4obxEsnw4bBffeFPuh69cL/MPWFUiFWrAiXduJEuO46GDAgVDkVSTfJuvNaB2CWu6+KPV5lZnUAYrdfF/cidx/o7tnunl2rVq0EhRqRHdMZlywJBXZ2TGfUPPe4e/vt0F00bVroKho6VAlBMlOUSeFadnYdQZj6mhO7nwOMTnhEyea++3bOb99hw4ZwXOJi61b4wx/gwgtDiYoZM0ItI5FMFUnpbDOrDlwA/KrI4T7ASDO7AVgCdIwitqSi6YwVavly+MUvYNIkuP56eOopqF496qhEohVJUnD39UCN3Y6tJsxGkh3q1St+4ZOmM+63t96CX/4yVDkdOjSMIYhI9LOPZG80nTHutm4NvW/t20Pt2pCXp4QgUpSSQjLTdMa4WrYMzj0X/t//gxtvDDWMGjWKOiqR5KLtOJNd585KAnHw5puhu+iHH8L+B126RB2RSHJSS0HS2tat8LvfQYcOUKdO6C5SQhApmVoKkrYWLw6zi6ZODcs7+vWDH/0o6qhEkpuSgqSll1+Gm24Ka/5GjIBOnaKOSCQ1qPtI0sqGDfCrX4XNcBo2DDujKSGIlJ6SgqSNefOgVaswQeu3v4X33oPjj486KpHUou4jSXnu8Pe/hy0yDz0Uxo0rxb7JIlIstRQkpa1ZA1ddBd27Q9u2MHeuEoLI/lBSKK9hw8L+uwccEG5VuTThpkwJlU3HjIFHH4WxY8MqZREpPyWF8lBJ60ht2xa2yGzbFqpUgQ8+gLvuCvlZRPaP/hmVh0paR2bZsrAr2v33h1lFs2aFwWURiQ8NNJeHSlpH4tVXQ4nrjRthyJBQyM4s6qhE0otaCuVRUulqlbSuEBs3wu23wyWXhEs8cybk5CghiFQEJYXyUEnrhFm4EE4/Hfr3D4lh6lQ48cSooxJJX0oK5aGS1hXOHZ55Bk45BfLzwwyjfv3goIOijkwkvWlMobxU0rrCFBTADTeEMYQLLwzjB3XqRB2VSGZQS0GSyrhx0LRp2C7ziSfgjTeUEEQSSUlBksLGjaFMxU9/CjVqwIwZcMcdWnsgkmjqPpLIzZ8f9j346CO49Vb485+174FIVPT/MImMO/z1r5CdDStXwuuvw1NPKSGIREktBYnEqlXQrVuoV9ShAwwerLpFIslALQVJuLFjw2DyhAmhZfD660oIIslCSUES5ocf4Lbb4OKLQxLIywtjCFqZLJI8lBQkIT7+GE49NbQM7rgDPvwQGjeOOioR2Z2SglSo7dvDSuRWrcKitDfeCOsPqlaNOjIRKY4GmqXCfPUVdO0K77wDP/85DBoEtWpFHZWI7E0kLQUzO8zMRpnZJ2a20MxON7MjzGy8mS2K3R4eRWyy/9xh+HBo0gSmT4d//ANGj1ZCEEkFUXUfPQm86e4NgWbAQqAXMMHdGwATYo8lxaxZA9deG8pCnXRS2DP5xhs1mCySKhKeFMzsUOBsYBCAu29297XApcDQ2GlDgcsSHZvsn3HjQuvgX/8KVcQnT4Yf/zjqqESkLKJoKRwHFACDzWy2mT1rZtWB2u6+InbOSqDYmetmlmtmeWaWV1BQkKCQZW82bIAePULdokMPDV1G994LlTRiJZJyokgKlYCWwNPu3gJYz25dRe7ugBf3Yncf6O7Z7p5dS53UkcvLg5YtQ7mK228Pu6K1bBl1VCJSXlEkhXwg392nxx6PIiSJVWZWByB2+3UEsUkpbd0KDz8cdkVbvx7Gjw9TT1W3SCS1JTwpuPtK4Csz27Gp4nnAAmAMkBM7lgOMTnRsUjqLFsFZZ8H990PHjqG66fnnRx2ViMRDVL2+PYBhZlYF+AK4npCgRprZDcASoGNEsUkJ3MOuo3feCVWqwIgR0KlT1FGJSDxFkhTcfQ6QXcxT5yU6FimdFSvC1NKxY+GCC0JV02OOiToqEYk3lbmQfRo1Kkw1fecd6N8f3nxTCUEkXSkpSIlWrw4L0a6+GrKyYPbsMPVUW2SKpC/985ZivfZaqGI6alSYZTR1KjRsGHVUIlLRtLxIdvHtt6G09ZAhYSOcN96A5s2jjkpEEkUtBSk0fnwYO3j++bAi+cMPlRBEMo2SgrBuHdxyC1x4IVSvHrqKeveGgw6KOjIRSTQlhQw3eTI0awbPPBPWH8yaFXZIE5HMpKSQoX74ISSBdu3C40mT4C9/UZkKkUyngeYMNH065OTAp5+GbqO+feHgg6OOSkSSgVoKGWTTpjCAfMYZodz1+PEwYIASgojspJZChpg9O7QOPv4YunWDxx8Pex+IiBSllkKa27QJ/vCHMHhcUBAWpQ0apIQgIsVTSyGNzZgB118P8+fDddfBE0/AEUdEHZWIJDO1FNLQxo3Qqxe0bg1r14bWwdChSggism9qKaSZqVPDmMEnn8ANN4RppuoqEpHSUkshTWzYAL/5DZx5Zrj/1lvw7LNKCCJSNmoppIH33gutg88/h5tvhj//GQ45JOqoRCQVqaWQwtavh9tug7ZtYds2mDABnn5aCUFEyk9JIUVNnBgqmj71FNx6K3z0EZx7btRRiUiqU1JIMd9/D927hwRw4IGhoF3//lqVLCLxoaSQQsaNC7uh/f3voZjd3LnQpk3UUYlIOlFSSAGrV0PXrvDTn4Yqpu+/H6aaVqsWdWQikm6UFJKYO7z0Epx0EgwbBvfdB3PmwOmnRx2ZiKQrTUlNUvn5oaz1q69CdnboOmrWLOqoRCTdqaWQZLZvD9NKTzoJ3n47dBNNnaqEICKJoZZCEvnkE7jpJpgyBc4/PwwoH3981FGJSCZRSyEJbNkCvXuH1sD8+TB4cOguUkIQkUSLpKVgZouB74FtwFZ3zzazI4CXgCxgMdDR3f8XRXyJNGNGKFz38cfQsSM8+SQcdVTUUYlIpoqypXCOuzd39+zY417ABHdvAEyIPU5b69eHAnatW4cpp6NHh5lGSggiEqVk6j66FBgauz8UuCzCWCrU+PGhRMXjj0NuLixYAJdcEnVUIiLRJQUHxpnZTDPLjR2r7e4rYvdXArWLe6GZ5ZpZnpnlFRQUJCLWuNmxCO3CC6FyZZg0Kcw0UnlrEUkWUSWFs9y9JdAB+LWZnV30SXd3QuLYg7sPdPdsd8+uVatWAkLdf+7w/PPQsGFYhHbvvaFExdln7/u1IiKJFElScPdlsduvgVeAU4FVZlYHIHb7dRSxxdtnn4XppTk5cMIJMHt2mGlUtWrUkYmI7CnhScHMqpvZITvuAxcC84AxQE7stBxgdKJji6dNm+Dhh6FpU5g5E555JmyG07hx1JGJiJQsiimptYFXzGzH7x/u7m+a2QxgpJndACwBOkYQW1xMngy/+lVYjHbNNfDEE1CnTtRRiYjsW8KTgrt/AexRtMHdVwPnJTqeeFqzBu65BwYNgqwsGDsWOnSIOioRkdJLpimpKcsd/vnPMJA8ZEhIDPPnKyGISOpR7aP9tGhR2AltwgQ47bRQxK5p06ijEhEpH7UUymnzZnjkkbAIbcYM+NvfwuY3SggiksrUUiiH994LA8kLF8LVV0O/fnD00VFHJSKy/9RSKIOCAujWLSw627ABXnsNRo5UQhCR9KGkUArbt8PAgXDiifDCC3D33WEg+eKLo45MRCS+1H20D7NmhYHkDz+Etm1hwAA4+eSooxIRqRhqKZRg7Vro0QNatYLFi0MLYeJEJQQRSW9qKezGHYYPD3sdfP013HJLmGV02GFRRyYiUvGUFIpYuDAkgXffDS2E11+HU06JOioRkcRR9xFhF7Tf/S6sMZgzJ4r+CwkAAAXoSURBVBSvmzpVCUFEMk9GtxTcwzaYt98OS5eGDXD69oUjj4w6MhGRaGRsUvjiC7jtttBF1LhxqGzapk3UUYmIRCsju4+eey7MIpo0CR57LEw7VUIQEcnQlsIJJ8DPfw6PPw5160YdjYhI8sjIpHDWWeFHRER2lZHdRyIiUjwlBRERKaSkICIihZQURESkkJKCiIgUUlIQEZFCSgoiIlJISUFERAqZu0cdQ7mZWQGwpJwvrwl8E8dwKloqxZtKsUJqxZtKsUJqxZtKscL+xVvf3WsV90RKJ4X9YWZ57p4ddRyllUrxplKskFrxplKskFrxplKsUHHxqvtIREQKKSmIiEihTE4KA6MOoIxSKd5UihVSK95UihVSK95UihUqKN6MHVMQEZE9ZXJLQUREdqOkICIihTImKZjZYWY2ysw+MbOFZna6mR1hZuPNbFHs9vCo44QSY/2jmS0zszmxn4uijhPAzE4sEtMcM/vOzO5Ixmu7l1iT8toCmFlPM5tvZvPMbISZVTWz48xsupl9bmYvmVmVqOOEEmMdYmZfFrm2zaOOE8DMbo/FOd/M7ogdS7rP7A4lxFshn9uMGVMws6HAe+7+bOwfUTXgXmCNu/cxs17A4e7+20gDpcRY7wDWuftj0UZXMjM7EFgGnAb8miS8tjvsFuv1JOG1NbNjgCnASe7+g5mNBMYCFwH/dvcXzewZYK67P52ksbYDXnP3UVHGV5SZNQZeBE4FNgNvAjcDuSThZ3Yv8XahAj63GdFSMLNDgbOBQQDuvtnd1wKXAkNjpw0FLosmwp32EmsqOA/4r7svIQmv7W6KxprMKgE/MrNKhP8crADOBXZ8ySbTtd091uURx1OSRsB0d9/g7luBScAVJO9ntqR4K0RGJAXgOKAAGGxms83sWTOrDtR29xWxc1YCtSOLcKeSYgW41cw+MrPnkqlpW0QnYETsfjJe26KKxgpJeG3dfRnwGLCUkAy+BWYCa2NfDgD5wDHRRLhTcbG6+7jY071j1/YJMzsosiB3mge0MbMaZlaN0PI6luT9zJYUL1TA5zZTkkIloCXwtLu3ANYDvYqe4KEfLRn60kqK9Wngx0Bzwj+6v0QWYTFi3VyXAC/v/lwSXVug2FiT8trG/pFfSviPwtFAdaB9pEGVoLhYzawL8DugIdAKOAKIvDvG3RcCfYFxhK6YOcC23c5Jms/sXuKtkM9tpiSFfCDf3afHHo8ifPGuMrM6ALHbryOKr6hiY3X3Ve6+zd23A/8g9C8mkw7ALHdfFXucjNd2h11iTeJrez7wpbsXuPsW4N/AmcBhsS4agLqEsZGoFRfrGe6+woNNwGCS5Nq6+yB3P8Xdzwb+B3xGEn9mi4u3oj63GZEU3H0l8JWZnRg7dB6wABgD5MSO5QCjIwhvFyXFuuPDGnM5oUmZTK5l1+6YpLu2RewSaxJf26VAazOrZmbGzs/tROCq2DnJcm2Li3VhkS9ZI/TRJ8W1NbMjY7f1CP3zw0niz2xx8VbU5zaTZh81B54FqgBfEGacHACMBOoRSnB3dPc1kQUZU0Ks/QnNRAcWA78q0v8ZqdiYx1LgeHf/NnasBsl5bYuL9QWS99o+CFwDbAVmAzcSxhBeJHTHzAa6xP4nHqkSYn0DqAUYodvjZndfF1mQMWb2HlAD2ALc6e4TkvUzCyXGWyGf24xJCiIism8Z0X0kIiKlo6QgIiKFlBRERKSQkoKIiBRSUhARkUJKCiJxYmbHxiqCHhF7fHjscVa0kYmUnpKCSJy4+1eE0gN9Yof6AAPdfXFkQYmUkdYpiMSRmVUmFK17DrgJaB4r+yCSEirt+xQRKS1332JmdxMKl12ohCCpRt1HIvHXgVC1snHUgYiUlZKCSBzF6lZdALQGeu5WtEwk6SkpiMRJrBLo08Ad7r4UeJSw8YxIylBSEImfm4Cl7j4+9vhvQCMzaxthTCJlotlHIiJSSC0FEREppKQgIiKFlBRERKSQkoKIiBRSUhARkUJKCiIiUkhJQURECv1/l7W8DA6cj1UAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrsEU8-dVzKD","executionInfo":{"status":"ok","timestamp":1639374667417,"user_tz":-540,"elapsed":55160,"user":{"displayName":"임경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14795974998298105210"}},"outputId":"72de8a1d-54dd-4b78-a6ad-397ff303f8a5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd \n","from sklearn import model_selection\n","from sklearn import metrics\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","import tensorflow as tf\n","import numpy as np\n","\n","\n","file_path='/content/drive/MyDrive/act3.csv'\n","df=pd.read_csv(file_path)\n","#display(df)\n","\n","X1 =df.iloc[:,2:5]#science\n","#X2=df.iloc[:,2]#eng\n","#X3=df.iloc[:,3]#ma\n","Y = df.iloc[:,1]#lev\n","\n","x_train, x_test, y_train, y_test = model_selection.train_test_split(X1, Y, test_size=0.3)\n","\n","\n","#3) science, english, math를 특징 데이터(x_data)로하고 level을 클래스분류 데이터 (y_data)로 설정하자. \n","#Decision tree를 이용하여 아래와 같이 train score, test score를 계산해보고 모델을 검증을 해보자. [3]\n","#- decision tree의 파라미터는 각자 결정한다.\n","#- 데이터분할(7:3)\n","#- 결과에 대한 분석내용을 추가할 것\n","estimator = DecisionTreeClassifier(criterion='gini', max_depth=10, max_leaf_nodes=None, \n","min_samples_split=2, \n","min_samples_leaf=1, \n","max_features=None)\n","\n","estimator.fit(x_train, y_train)\n","\n","\n","y_predict = estimator.predict(x_train) \n","score = metrics.accuracy_score(y_train, y_predict)\n","print('train score: ', score)\n","\n","y_predict = estimator.predict(x_test) \n","score = metrics.accuracy_score(y_test, y_predict)\n","print('test score: ', score)\n","print('[')\n","print(x_test)\n","print(']')\n","print(y_test)\n","print(classification_report(y_test, y_predict))\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_1IvpVVvgo6","executionInfo":{"status":"ok","timestamp":1639383202643,"user_tz":-540,"elapsed":474,"user":{"displayName":"임경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14795974998298105210"}},"outputId":"b0b4a365-d861-4e1e-d4d5-b8b2b246800c"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["train score:  1.0\n","test score:  0.2\n","[\n","    science  english  math\n","1        62       66    65\n","10       67       65    76\n","0        92       98    97\n","9        83       82    85\n","4        65       66    69\n","]\n","1     A\n","10    C\n","0     A\n","9     C\n","4     B\n","Name: class, dtype: object\n","              precision    recall  f1-score   support\n","\n","           A       0.25      0.50      0.33         2\n","           B       0.00      0.00      0.00         1\n","           C       0.00      0.00      0.00         2\n","\n","    accuracy                           0.20         5\n","   macro avg       0.08      0.17      0.11         5\n","weighted avg       0.10      0.20      0.13         5\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["\n","import pandas as pd \n","from sklearn import model_selection\n","from sklearn import metrics\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","import tensorflow as tf\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","\n","file_path='/content/drive/MyDrive/act3.csv'\n","df=pd.read_csv(file_path)\n","#display(df)\n","\n","\n","\n","\n","\n","X1 =df.iloc[:,2:5]#science\n","#X2=df.iloc[:,2]#eng\n","#X3=df.iloc[:,3]#ma\n","Y = df.iloc[:,5]#lev\n","\n","print(Y)\n","df = pd.get_dummies(df)\n","\n","x_train, x_test, y_train, y_test = model_selection.train_test_split(X1, Y, test_size=0.3)\n","#로지스틱 모델링 \n","#규제정도가 되는 C값은 1로 사용하고 규제방법(regularization penality)\n","# 은 default인 l2(ㅣ2-norm)를 사용 \n","#max_iter는 계산에 사용할 작업 수\n","estimator = LogisticRegression(C=1, max_iter=10000)\n","estimator.fit(x_train, y_train)\n","# train 평가 \n","y_predict = estimator.predict(x_train)\n","score = metrics.accuracy_score(y_train, y_predict) #classification\n","print('train score: ', score)\n","# test 평가 \n","y_predict = estimator.predict(x_test)\n","score = metrics.accuracy_score(y_test, y_predict)\n","print('test score: ', score)\n","\n","\n","# 모델 적용 \n","print(x_test[:2])#첫번째, 두번째 행\n","y_predict = estimator.predict(x_test[:2])\n","print(y_predict) \n","for y1, y2 in zip(y_test, y_predict):\n"," print(y1, y2, y1==y2)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoEbh1Aw1hfS","executionInfo":{"status":"ok","timestamp":1639384814886,"user_tz":-540,"elapsed":287,"user":{"displayName":"임경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14795974998298105210"}},"outputId":"30fb91ab-e061-40c2-f72f-e85dc3a714e9"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["0     1\n","1     0\n","2     1\n","3     0\n","4     0\n","5     1\n","6     1\n","7     0\n","8     1\n","9     1\n","10    0\n","11    0\n","12    1\n","13    1\n","14    1\n","Name: Pass, dtype: int64\n","train score:  1.0\n","test score:  1.0\n","   science  english  math\n","9       83       82    85\n","6       91       90    92\n","[1 1]\n","1 1 True\n","1 1 True\n"]}]}]}